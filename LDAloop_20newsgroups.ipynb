{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA loop over n_topics for labelled documents from 20 NewsGroups dataset to check perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np; import pandas as pd; import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import codecs \n",
    "from glob import glob\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import pyorient\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "import string\n",
    "import re\n",
    "# random\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORTING DOCS FROM 20 NEWSGROUPS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism',\n",
    "'comp.graphics',\n",
    "'comp.os.ms-windows.misc',\n",
    "'comp.sys.ibm.pc.hardware',\n",
    "'comp.sys.mac.hardware',\n",
    "'comp.windows.x',\n",
    "'misc.forsale',\n",
    "'rec.autos',\n",
    "'rec.motorcycles',\n",
    "'rec.sport.baseball',\n",
    "'rec.sport.hockey',\n",
    "'sci.crypt',\n",
    "'sci.electronics',\n",
    "'sci.med',\n",
    "'sci.space',\n",
    "'soc.religion.christian',\n",
    "'talk.politics.guns',\n",
    "'talk.politics.mideast',\n",
    "'talk.politics.misc',\n",
    "'talk.religion.misc']\n",
    "\n",
    "min_n_topics = 20\n",
    "max_n_topics = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers','quotes'),\n",
    "                                      categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cwd_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### TOTAL NUMBER OF DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_docs = newsgroups_train.filenames.shape[0]\n",
    "n_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LDA to find the topic most-associated with each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 From Strings to Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization WITHOUT Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "tf_vectorizer = CountVectorizer(encoding='utf-8', analyzer='word', stop_words='english',\n",
    "                                ngram_range = (1,1), max_df=0.95, min_df = 50, token_pattern = '[a-zA-Z]{2,}').fit(newsgroups_train.data)\n",
    "tf_docs = tf_vectorizer.transform(newsgroups_train.data)\n",
    "print(\"fit vectorizer without lemmatization done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WITH TFIDF (active/deactivate following cell to perform/not perform TFIDF)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "tfidf_vectorizer = TfidfTransformer(sublinear_tf=False, use_idf = True).fit(tf_docs)\n",
    "tf_docs = tfidf_vectorizer.transform(tf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = len(tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 LDA implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_topics_loop = range(min_n_topics, max_n_topics+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Fitting LDA models with tf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_docs, n_features))\n",
    "\n",
    "perplexity = []\n",
    "\n",
    "for i_topics in n_topics_loop:\n",
    "    lda = LatentDirichletAllocation(n_topics=i_topics, max_iter=10, \n",
    "                                    learning_method='batch', learning_offset=50.,\n",
    "                                    evaluate_every=1, n_jobs=-1, random_state=1)\n",
    "    t0 = time()\n",
    "    lda.fit(tf_docs)\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))\n",
    "    # printing the vocabularies\n",
    "    print(\"\\nTopics in LDA model:\")\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    print_top_words(lda, tf_feature_names, n_top_words)\n",
    "    # perplexity model\n",
    "    perplexity.append(lda.perplexity(tf_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
    "\n",
    "axes.plot(n_topics_loop, perplexity, 'rd-')\n",
    "\n",
    "# Set label for axis x\n",
    "axes.set_xlabel('# Topics')\n",
    "# Set label for axis y\n",
    "axes.set_ylabel('Perplexity')\n",
    "# Set the title\n",
    "axes.set_title('LDA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig.savefig(cwd_path +'/results/LDA_perpl_vs_topic.png', dpi = 200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
